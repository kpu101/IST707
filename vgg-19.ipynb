{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I have run the model with 25 samples, it works fine but I couldn't run it on the whole dataset because it takes too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-18T09:28:58.183627Z",
     "iopub.status.busy": "2022-03-18T09:28:58.183287Z",
     "iopub.status.idle": "2022-03-18T09:29:00.779747Z",
     "shell.execute_reply": "2022-03-18T09:29:00.778955Z",
     "shell.execute_reply.started": "2022-03-18T09:28:58.183547Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import models\n",
    "from collections import OrderedDict\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T09:29:12.747435Z",
     "iopub.status.busy": "2022-03-18T09:29:12.74709Z",
     "iopub.status.idle": "2022-03-18T09:29:12.75386Z",
     "shell.execute_reply": "2022-03-18T09:29:12.75307Z",
     "shell.execute_reply.started": "2022-03-18T09:29:12.747398Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = '../input/animals10/raw-img/'\n",
    "translate = {\"cane\": \"dog\", \"cavallo\": \"horse\", \"elefante\": \"elephant\", \"farfalla\": \"butterfly\",\n",
    "             \"gallina\": \"chicken\", \"gatto\": \"cat\", \"mucca\": \"cow\", \"pecora\": \"sheep\", \n",
    "             \"ragno\": \"spider\", \"scoiattolo\": \"squirrel\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T09:29:14.189026Z",
     "iopub.status.busy": "2022-03-18T09:29:14.188741Z",
     "iopub.status.idle": "2022-03-18T09:29:35.399265Z",
     "shell.execute_reply": "2022-03-18T09:29:35.398521Z",
     "shell.execute_reply.started": "2022-03-18T09:29:14.188991Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare transforms\n",
    "\n",
    "my_transform = transforms.Compose([transforms.RandomRotation(45),\n",
    "                                     transforms.RandomRotation(30),\n",
    "                                     transforms.RandomResizedCrop(1080),\n",
    "                                     transforms.Resize(512),\n",
    "                                     transforms.Resize(224),\n",
    "                                     transforms.RandomRotation(45),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "# train_data is whole data for now\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path,\n",
    "                                              transform=my_transform)\n",
    "\n",
    "\n",
    "def create_subsets(train_set): # create a simple list which holds nums from 1 to length of data\n",
    "    temp_list = list()\n",
    "    for i in range(len(train_data)):\n",
    "        temp_list.append(i)\n",
    "    temp_list = np.array(temp_list)\n",
    "    np.random.shuffle(temp_list) # shuffle the list and by using this list create subsets (train and test data)\n",
    "    \n",
    "    fold = len(train_data)/5\n",
    "    \n",
    "    subset_train = Subset(train_data, temp_list[0:int(fold*4)]) # train set\n",
    "    subset_test = Subset(train_data, temp_list[int(fold*4):]) # test set\n",
    "    \n",
    "    return subset_train, subset_test\n",
    "\n",
    "\n",
    "def create_data_loaders(mini_batch_size, subset_trian, subset_test):\n",
    "    # create data loaders with given values\n",
    "    train_data_loader = data.DataLoader(subset_train, shuffle=True, batch_size=mini_batch_size) \n",
    "    test_data_loader  = data.DataLoader(subset_test, shuffle=True, batch_size=mini_batch_size)\n",
    "    \n",
    "    return train_data_loader, test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T09:29:38.551885Z",
     "iopub.status.busy": "2022-03-18T09:29:38.55113Z",
     "iopub.status.idle": "2022-03-18T09:29:38.559425Z",
     "shell.execute_reply": "2022-03-18T09:29:38.558456Z",
     "shell.execute_reply.started": "2022-03-18T09:29:38.551846Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(unfreeze_all_layers): # if unfreeze_all_layers = True unfreeze_all else unfreeze only fully connecteds\n",
    "    model = torchvision.models.vgg19(pretrained=True)\n",
    "\n",
    "        \n",
    "\n",
    "    model.classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 6000)),('relu', nn.ReLU()), # add fully connected 1\n",
    "                                         ('dropout', nn.Dropout(.5)), \n",
    "                                         ('fc2', nn.Linear(6000, 10)), # add fully connected 2\n",
    "                                         ('output', nn.Softmax(dim=1) )])) # outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(unfreeze_all_layers): # Case unfreeze all layers\n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = True \n",
    "    else: # # unfreeze only fully connected layers\n",
    "        for name, param in model.named_parameters():\n",
    "            if(name=='classifier.fc1.weight' or name=='classifier.fc1.bias' or name=='classifier.fc2.weight' \n",
    "               or name=='classifier.fc2.bias'):\n",
    "                param.requires_grad = True\n",
    "        \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T09:29:41.023165Z",
     "iopub.status.busy": "2022-03-18T09:29:41.022514Z",
     "iopub.status.idle": "2022-03-18T09:29:41.028301Z",
     "shell.execute_reply": "2022-03-18T09:29:41.027414Z",
     "shell.execute_reply.started": "2022-03-18T09:29:41.023128Z"
    }
   },
   "outputs": [],
   "source": [
    "def gpu_optimizer(model):\n",
    "    train_on_gpu = torch.cuda.is_available()\n",
    "    # add optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.008, amsgrad=True)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    loss_lst, loss_val_lst = [], []\n",
    "    \n",
    "    return train_on_gpu, optimizer, loss_fn, loss_lst, loss_val_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T09:29:43.587139Z",
     "iopub.status.busy": "2022-03-18T09:29:43.586875Z",
     "iopub.status.idle": "2022-03-18T09:29:43.596355Z",
     "shell.execute_reply": "2022-03-18T09:29:43.595652Z",
     "shell.execute_reply.started": "2022-03-18T09:29:43.587108Z"
    }
   },
   "outputs": [],
   "source": [
    "def seq (model, df, name, optimizer): \n",
    "    train_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    for batch_i, (data, target) in enumerate(df):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            model.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = loss_fn(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        if name == 'train': \n",
    "            loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss \n",
    "        train_loss += loss.item()\n",
    "        _, pred = torch.max(output, 1) \n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "        for i in range(len(target.data)):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "        \n",
    "    return class_correct, class_total, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T09:29:48.431036Z",
     "iopub.status.busy": "2022-03-18T09:29:48.430744Z",
     "iopub.status.idle": "2022-03-18T09:29:48.438681Z",
     "shell.execute_reply": "2022-03-18T09:29:48.438031Z",
     "shell.execute_reply.started": "2022-03-18T09:29:48.431001Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainModel(model, train_loader,valid_loader, optimizer, num_epochs): \n",
    "    # number of epochs to train the model\n",
    "    n_epochs = num_epochs\n",
    "    print('started')\n",
    "    for epoch in range(1, n_epochs+1):     \n",
    "        train_loss = 0.0\n",
    "        class_correct = list(0. for i in range(10))\n",
    "        class_total = list(0. for i in range(10))\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "       # Repeat for each batch in the training set\n",
    "        model.train()\n",
    "        class_correct, class_total, train_loss= seq(model,  train_loader, 'train', optimizer)\n",
    "        printdata(class_correct, class_total, train_loss, epoch, 'train', train_loader)\n",
    "        # Repeat for each validation batch \n",
    "        ###################\n",
    "        # validate the model #\n",
    "        ###################\n",
    "        model.eval()\n",
    "        class_correct, class_total, train_loss= seq(model, valid_loader, 'validation', optimizer)\n",
    "        printdata(class_correct, class_total, train_loss, epoch, 'validation', valid_loader)\n",
    "    torch.save(model.state_dict(), 'model.pt')        \n",
    "    print(f'model saved ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T09:29:50.247876Z",
     "iopub.status.busy": "2022-03-18T09:29:50.247161Z",
     "iopub.status.idle": "2022-03-18T09:29:50.253112Z",
     "shell.execute_reply": "2022-03-18T09:29:50.252181Z",
     "shell.execute_reply.started": "2022-03-18T09:29:50.247838Z"
    }
   },
   "outputs": [],
   "source": [
    "def printdata(class_correct, class_total, train_loss, epoch, name, df ): \n",
    "    print(f'Epoch %d, loss: %.8f \\t{name} Accuracy (Overall): %2d%% (%2d/%2d)' %(epoch,\n",
    "        train_loss / len(df), 100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T09:29:52.531878Z",
     "iopub.status.busy": "2022-03-18T09:29:52.531117Z",
     "iopub.status.idle": "2022-03-18T09:29:52.542944Z",
     "shell.execute_reply": "2022-03-18T09:29:52.542277Z",
     "shell.execute_reply.started": "2022-03-18T09:29:52.531837Z"
    }
   },
   "outputs": [],
   "source": [
    "subset_train, subset_test = create_subsets(train_data)\n",
    "train_data_loader, test_data_loader = create_data_loaders(128, subset_train, subset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T09:29:54.32282Z",
     "iopub.status.busy": "2022-03-18T09:29:54.321985Z",
     "iopub.status.idle": "2022-03-18T09:34:47.381649Z",
     "shell.execute_reply": "2022-03-18T09:34:47.380212Z",
     "shell.execute_reply.started": "2022-03-18T09:29:54.32278Z"
    }
   },
   "outputs": [],
   "source": [
    "# CASE 1: MODEL CREATED, ALL LAYERS UNFREEZED\n",
    "model1 = create_model(True) \n",
    "print(model1)\n",
    "train_on_gpu, optimizer, loss_fn, loss_lst, loss_val_lst = gpu_optimizer(model1)\n",
    "trainModel(model1, train_data_loader, test_data_loader, optimizer, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cASE 2: MODEL CREATED, ONLY FULLY CONNECTED LAYERS UNFREEZED\n",
    "model2 = create_model(False) # only fully connected unfreezed \n",
    "print(model2)\n",
    "train_on_gpu, optimizer, loss_fn, loss_lst, loss_val_lst = gpu_optimizer(model2)\n",
    "trainModel(model2, train_data_loader, test_data_loader, optimizer, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
